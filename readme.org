#+title: ELLM - Emacs Local LLM Interface
#+author: 
#+date: 2024

* Overview

ELLM is an Emacs package to interact with a local Ollama LLM server. It provides a simple interface to send prompts to and receive responses from various language models served by Ollama.

Inspired by [[https://github.com/xenodium/chatgpt-shell][chatgpt-shell]].

* Requirements

- Emacs 27.1 or later
- markdown-mode 2.3 or later
- A running Ollama server (default: http://localhost:11434)
- spinner.el (optional, for progress indicators)

* Installation

** Manual Installation

Clone this repository:

#+begin_src bash
git clone https://github.com/yourusername/ellm.el.git ~/.emacs.d/site-lisp/ellm
#+end_src

Add to your Emacs configuration:

#+begin_src emacs-lisp
(add-to-list 'load-path "~/.emacs.d/site-lisp/ellm")
(require 'ellm)
#+end_src

** Using use-package

#+begin_src emacs-lisp
(use-package ellm
  :load-path "~/.emacs.d/site-lisp/ellm")
#+end_src

* Usage

** Interactive Chat

To start an interactive session with Ollama:

#+begin_src
M-x ellm
#+end_src

This will open a new buffer where you can enter prompts and receive responses.

** Other Entry Points

- ~M-x ellm-region~ - Send the selected region to Ollama
- ~M-x ellm-buffer~ - Send the entire buffer to Ollama
- ~M-x ellm-git-commit~ - Generate a git commit message based on staged changes

* Configuration

Customize the package with the following variables:

#+begin_src emacs-lisp
;; Change the default model
(setq ellm-model "llama3")

;; Change the Ollama server URL
(setq ellm-base-url "http://localhost:11434")

;; Change how the buffer is displayed
(setq ellm-display-function #'switch-to-buffer)

;; Enable/disable markdown rendering in responses
(setq ellm-markdown-rendering t)

;; Change the spinner type (requires spinner.el)
(setq ellm-spinner-type 'progress-bar)

;; Set the maximum number of history entries to keep
(setq ellm-history-max-entries 50)
#+end_src

* Key Bindings

| Key     | Function            | Description                        |
|---------+---------------------+------------------------------------|
| RET     | ellm-send           | Send prompt to Ollama              |
| C-c C-c | ellm-send           | Send prompt to Ollama              |
| C-c C-k | ellm-cancel         | Cancel the current request         |
| C-c C-q | ellm-quit           | Quit the ELLM buffer               |
| C-c C-n | ellm-next-prompt    | Move to the next prompt            |
| C-c C-p | ellm-previous-prompt | Move to the previous prompt       |
| C-c C-m | ellm-select-model   | Select an Ollama model to use      |
| C-c C-r | ellm-clear-buffer   | Clear the buffer and start fresh   |

* Ollama Models

The package will attempt to fetch a list of available models from your local Ollama server. If you want to use a specific model:

#+begin_src emacs-lisp
;; Set default model
(setq ellm-model "llama3")

;; Or select interactively
M-x ellm-select-model
#+end_src

* License

This project is licensed under the GPL-3.0 License - see the LICENSE file for details.